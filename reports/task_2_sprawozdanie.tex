% vim:encoding=utf8 ft=tex sts=2 sw=2 et:

\documentclass{classrep}
\usepackage[utf8x]{inputenc}
\usepackage{color}
\usepackage{listings}
\usepackage{mathtools}
\lstloadlanguages{Python}
\lstset{breaklines=true}

\studycycle{Informatyka, studia niestacjonarne, mgr II st.}
\coursesemester{I}

\coursename{Obliczenia inteligentne}
\courseyear{2015/2016}

\courseteacher{dr inż. Kamil Stokfiszewski}
\coursegroup{Niedziela, 13.45}

\author{
  \studentinfo{Szymon Łyszkowski}{206809}\and
  \studentinfo{Piotr Kluch}{206799}
}

\title{Zadnie nr 2. Sieć Kohonena kompresująca obrazy.}

\begin{document}
\maketitle

\section{Cel}
{
Głównym celem zadania było zapoznanie z zasadą działania sieci neuronowej Kohonena oraz jej implementacja. Od sieci oczekuje się, że będzie w stanie dokonać kompresji obrazu w skali szarości. Kompresja ma być przeprowadzona poprzez uprzedni trening gdzie danymi wejściowymi są losowe części obrazu wejściowego a następnie zakodowanie w postaci struktury danych. Struktura danych, która jest kompresją obrazu może być zdekodowana przez sieć.}

\section{Wprowadzenie}
{Sieć Kohonena jest de facto identyczna w swojej strukturze jak sieć MADALINE. Sieć Kohonena nie posiada funkcji aktywacji dla poszczególnych neuronów klasyfikujących. Aby kompresować obrazy sieć w procesie uczenia przyjmuje na wejście macierz dwuwymiarową (w zależności od wariantu [4x4], [8x8] lub [16,16]). Taka macierz jest rozpłaszczana na wektor jednowymiarowy, który może zostać wymnożony z wagami każdego z neuronów (po uprzedniej normalizacji). Ilość wag w każdym neuronie jest iloczynem rozmiaru macierzy użytej podczas treningu oraz późniejszego kodowania skompresowanego obrazu. Proces uczenia jest realizowany metodą WTA\footnote{Winner Takes All}. Oznacza to, iż neuron, który odpowiedział na wyjściu największą wartością jest poddany procesowi nauki (zwiększenie wartości wag). Im więcej neuronów zostanie zmodyfikowane podczas procesu uczenia, tym dokładniejsze dane są zebrane o poszczególnych fragmentach obrazu co w efekcie daje mniejsze straty kompresji. Gdy proces uczenia jest zakończony następuje faza kodowania obrazu. Kodowanie polega na zapamiętaniu, który neuron koduje dany fragment obrazu. Dekodowanie jest przeskalowaniem wartości wag neuronu na dany fragment obrazu, który został nim zakodowany. Taki zdekodowany obszar jest wstawiany do obrazu wynikowego.
}

\section{Opis implementacji}
{Implementacja została przygotowana w języku Python. Cała sieć jest realizowana przez klasę KohonenNetwork (networks\slash kohonen\slash kohonen{\_}network.py), która realizuje proces uczenia. W swojej funkcjonalności wykorzystuje klasę ImageScanner (image{\_}utils\slash image{\_}scanner.py), która dostarcza losowe fragmenty obrazu dla procesu uczenia. Klasy: ImageFrameSlicer, ImageEncoder, ImageDecoder (w katalogu image{\_}utils\slash) są klasami pomocniczymi, ułatwiającymi manipulację stukturą danych, w której przechowywany jest obraz. Zadnie drugie jest realizowane w module task{\_}2.py (katalog tasks\slash): 
\begin{lstlisting}
if __name__ == '__main__':

kohonen_network = KohonenNetwork('../image_utils/images/lena-512-grayscale.bmp')
kohonen_network.train_kohonen_network(20000)

frame_slicer = ImageFrameSlicer(kohonen_network.image_array, kohonen_network._FRAME_SIZE)
frames_array = frame_slicer.create_list_of_flatten_frames()

image_encoder = ImageEncoder()
encoded_data_array = image_encoder.encode_image(kohonen_network, frames_array)

image_decoder = ImageDecoder(kohonen_network._FRAME_SIZE,frame_slicer.row_points,frame_slicer.column_points)
decoded_image_array = image_decoder.decode_image(kohonen_network.image_array.shape, kohonen_network.network_neurons, encoded_data_array)

img = Image.fromarray(decoded_image_array)
img.show()
img.save('../image_utils/kohonen_output_image.png')
\end{lstlisting}
Sieć jest najpierw trenowana losowymi fragmentami obrazu wejściowego. Następnym krokiem jest podzielenie obrazu wejściowego na fragmenty, które będą zakodowane poprzez wytrenowaną sieć kohonena. Tak zakodowany obraz jest przechowywany w zmiennej: 
\begin{lstlisting}
	encoded_data_array
\end{lstlisting}
Następnie struktura jest odkodowywana na obraz wynikowy dzięki ówcześnie wytrenowanej sieci.
}

\section{Materiały i metody}
{Litery, które mają być rozpoznawane przez sieć to binarne dwuwymiarowe tablice 4x4 wprowadzone do neuronów sieci. Przykładowa tablica wzorcowa dla litery "Y":
\begin{lstlisting}
def get_Y_four_by_four(self):
	y_sample_array = numpy.array([[1, 0, 0, 1],
				[0, 1, 1, 0],
				[0, 1, 0, 0],
				[1, 0, 0, 0]])
	return y_sample_array, 'Letter Y'
\end{lstlisting}
Implementacja programu obowiązuje rozpoznawanie liter: \textbf{T,V,W,X,Y,Z}. Wzorce tego typu zostały użyte do rozpoznawania liter wejściowych. Każdy wzorzec jest normalizowany i mapowany na wektor jednowymiarowy tak aby można było łatwo obliczyć wartość wyjścia wektora zgodnie ze wzorem:
\begin{center}$\sum_{i=1}^{n} x_iw_i$\end{center}

Każda próbka wejściowa, jest przetwarzana w ten sam sposób co wagi neuronu, tak aby na wyjściu wektora otrzymany skalar był z przedziału $<0,1>$.
\section{Wyniki}
{Poszczególne neurony sieci rozpoznają następujące litery:
\\Neuron of index 0 recognizes Letter T
\\Neuron of index 1 recognizes Letter V
\\Neuron of index 2 recognizes Letter W
\\Neuron of index 3 recognizes Letter X
\\Neuron of index 4 recognizes Letter Y
\\Neuron of index 5 recognizes Letter Z
\\Dla sieci przeprowadzone zostały testy dla następujących danych wejściowych:\\
\textbf{1)Podana próbka jest w pełni zgodna ze wzorcem litery "Z".}
\begin{lstlisting}
[1, 1, 1, 1]
[0, 0, 1, 0]
[0, 1, 0, 0]
[1, 1, 1, 1]

Neuron outputs: [0.79999999999999993, 0.55901699437494745,
0.5, 0.67082039324993692,
0.64549722436790291,
0.99999999999999989]
Neuron with highest output was: 1.0 and its index is 5
\end{lstlisting}
Litera jest rozpoznawana poprawnie.
\\
\textbf{2)Litera "Z", która posiada trzy "zaciemnione" - brakujące elementy wzorca.}  
\begin{lstlisting}
[1, 0, 0, 1]
[0, 0, 1, 0]
[0, 1, 0, 0]
[1, 1, 0, 1]

Neuron outputs: [0.59761430466719678, 0.53452248382484868,
0.59761430466719678, 0.80178372573727297,
0.77151674981045959, 0.83666002653407545]
Neuron with highest output was: 0.836660026534 and its index is 5
\end{lstlisting}
Przypadek ten jest także rozpoznawany poprawnie.
\\
\textbf{3)Litera "Y", która posiada jeden "zaciemniony" element oraz jeden dodatkowy (w tle):}
\begin{lstlisting}
[1, 0, 0, 1],
[0, 0, 1, 0],
[0, 1, 0, 0],
[1, 0, 0, 1]

Neuron outputs: [0.51639777949432231, 0.43301270189221941,
0.64549722436790291, 0.86602540378443871,
0.83333333333333359, 0.77459666924148352]
Neuron with highest output was: 0.866025403784 and its index is 3
\end{lstlisting} 
Jest rozpoznawana \textbf{niepoprawnie}, gdyż klasyfikowana jest jako "X". 
Jednakże dla przypadku bez dodatkowego elementu w tle:
\begin{lstlisting}
[1, 0, 0, 1]
[0, 0, 1, 0]
[0, 1, 0, 0]
[1, 0, 0, 0]

Neuron outputs: [0.56568542494923801, 0.47434164902525683,
0.56568542494923801, 0.79056941504209477,
0.9128709291752769, 0.70710678118654746]
Neuron with highest output was: 0.912870929175 and its index is 4
\end{lstlisting}
Jest już klasyfikowana poprawnie.	
}

\section{Dyskusja}
{Wyniki rozpoznawania przez sieć mogą być różne w zależności od zaciemnienia oraz podobieństwa do danych wzorcowych. Im większa rozdzielczość matrycy wzorcowej oraz danych wejściowych tym wynik może być dokładniejszy. Dla matrycy 4x4 pewne litery nie mogą być dobrze odwzorowane np. "W". Jednakże analiza większych matryc może być trudniejsza z racji na możliwe przesunięcie litery w dowolnym kierunku. Implementacja sieci nie bierze obsługuje takiego przypadku, który nie byłby zaklasyfikowany z uwagi na brak danych (sieć porównywałaby dane wejściowe z pustym obszarem we wzorcu). W takim przypadku należałoby zaimplementować centrowanie litery wejściowej lub porównywanie części matrycy wejściowej ze wzorcem co zdecydowanie niesie za sobą większy nakład obliczeniowy.}
\section{Wnioski}
{Rozdzielczość matrycy jest kluczowa dla rozpoznawania przypadków brzegowych (podobieństwo do dwóch lub więcej wzorców).}

\end{document}
